subDir_split <- paste("data_split",Sys.Date(),sep="_")
dir.create(file.path(subDir, subDir_split), showWarnings = FALSE) # create if !exists
# get filepath split directory for export
filepath_split <- paste(currDir, subDir, subDir_split, sep="/")
# d. export csv
# add csv extension to name
exportName <- paste0(temp_name,".csv")
# add filename.csv to the end of filepath so it can be used in write.csv as path
filepath_split <- paste(filepath_split,exportName,sep="/")
# write concatenated csv, leave off row numbers
write.csv(temp_df, filepath_split, row.names=FALSE)
# d. return dataframe to global environment
assign(temp_name,temp_df,.GlobalEnv)
# e. except instructions, add all the dataframes to 'totalData'
if(temp_name!="instructions") {totalData <- rbind(totalData,temp_df)}
}
assign("totalData", totalData, .GlobalEnv)
exportName <- paste0("totalData",".csv")
filepath_split <- paste(currDir, subDir, subDir_split, sep="/")
filepath_split <- paste(filepath_split,exportName,sep="/")
write.csv(totalData, filepath_split, row.names=FALSE)
}
split_by_trial_type(lgs, c("text", "single-stim", "survey-text"))
rm(instructions, surveyData, testData, totalData)
# df could be a dataframe in the global environment OR a filepath to a csv
split_by_trial_type <- function(df, type_list) {
# 1. check if df is a filepath ("character") or dataframe ("list")
if(typeof(df)=="character"){
setwd(dirname(df))
df <- read.csv(df) # setwd() to df's parent for saving future data
}
# some setup
type <- "trial_type" # CLDL standard colname for types
totalData <- data.frame() # empty dataframe for including data of type_list types
# 2. validate that inputs in correct format
validate_inputs <- function() {
# a. validate "trial_type" is col in df
if(type %in% names(df)) {
# b. validate types in type_list exist in type col
for (item in type_list) {
if(item %in% df[[type]]) {
# do nothing
} else {
print("ERR 1: one or more items in type_list were not found in dataframe")
return(FALSE)
}
}
}
else {
print("ERR 0: no column 'trial_type' found in dataframe, please name relevant column 'trial_type'")
return(FALSE)
}
return(TRUE) # return true if this point reached (return false would break from fxn early)
}
# ==== call fxn, continue only if validations return true! ====
if(validate_inputs() == FALSE){return(FALSE)} # return false breaks from the whole function early
# 3. separate data frames based on the type list, create a dataframe name/variable
for(item in type_list){
if(grepl("survey-text",item)){
temp_name <- "surveyData"
} else if (grepl("single-stim",item)){
temp_name <- "testData"
} else if (grepl("text", item)) {
temp_name <- "instructions"
} else if (grepl("categorize")) {
temp_name <- "trainingData"
} else {
temp_name <- paste(item, "Data", sep="") # if other type, just paste the type to Data
}
# b. create a dataframe for it by subsetting rows of that type
temp_df <- df[which(df[[type]]==item),]
# c. setup directory structure for exporting
# create or locate 'data' directory structure in the pwd
currDir <- getwd()
subDir <- "Data_processed"
dir.create(file.path(currDir, subDir), showWarnings = FALSE) # create data dir if !exists
# create sub directory for split data
subDir_split <- paste("data_split",Sys.Date(),sep="_")
dir.create(file.path(subDir, subDir_split), showWarnings = FALSE) # create if !exists
# get filepath split directory for export
filepath_split <- paste(currDir, subDir, subDir_split, sep="/")
# d. export csv
# add csv extension to name
exportName <- paste0(temp_name,".csv")
# add filename.csv to the end of filepath so it can be used in write.csv as path
filepath_split <- paste(filepath_split,exportName,sep="/")
# write concatenated csv, leave off row numbers
write.csv(temp_df, filepath_split, row.names=FALSE)
# d. return dataframe to global environment
assign(temp_name,temp_df,.GlobalEnv)
# e. except instructions, add all the dataframes to 'totalData'
if(temp_name!="instructions") {totalData <- rbind(totalData,temp_df)}
}
# total data
exportName <- paste0("totalData",".csv")
filepath_split <- paste(currDir, subDir, subDir_split, sep="/")
filepath_split <- paste(filepath_split,exportName,sep="/")
write.csv(totalData, filepath_split, row.names=FALSE)
}
split_by_trial_type("~/Desktop/totalData.csv",c("text","single-stim","survey-text"))
split_by_trial_type(lgs, c("text", "single-stim", "survey-text"))
# df could be a dataframe in the global environment OR a filepath to a csv
split_by_trial_type <- function(df, type_list = c("text", "single-stim", "survey-text")) {
# 1. check if df is a filepath ("character") or dataframe ("list")
if(typeof(df)=="character"){
setwd(dirname(df))
df <- read.csv(df) # setwd() to df's parent for saving future data
}
# some setup
type <- "trial_type" # CLDL standard colname for types
totalData <- data.frame() # empty dataframe for including data of type_list types
# 2. validate that inputs in correct format
validate_inputs <- function() {
# a. validate "trial_type" is col in df
if(type %in% names(df)) {
# b. validate types in type_list exist in type col
for (item in type_list) {
if(item %in% df[[type]]) {
# do nothing
} else {
print("ERR 1: one or more items in type_list were not found in dataframe")
return(FALSE)
}
}
}
else {
print("ERR 0: no column 'trial_type' found in dataframe, please name relevant column 'trial_type'")
return(FALSE)
}
return(TRUE) # return true if this point reached (return false would break from fxn early)
}
# ==== call fxn, continue only if validations return true! ====
if(validate_inputs() == FALSE){return(FALSE)} # return false breaks from the whole function early
# 3. separate data frames based on the type list, create a dataframe name/variable
for(item in type_list){
if(grepl("survey-text",item)){
temp_name <- "surveyData"
} else if (grepl("single-stim",item)){
temp_name <- "testData"
} else if (grepl("text", item)) {
temp_name <- "instructions"
} else if (grepl("categorize")) {
temp_name <- "trainingData"
} else {
temp_name <- paste(item, "Data", sep="") # if other type, just paste the type to Data
}
# b. create a dataframe for it by subsetting rows of that type
temp_df <- df[which(df[[type]]==item),]
# c. setup directory structure for exporting
# create or locate 'data' directory structure in the pwd
currDir <- getwd()
subDir <- "Data_processed"
dir.create(file.path(currDir, subDir), showWarnings = FALSE) # create data dir if !exists
# create sub directory for split data
subDir_split <- paste("data_split",Sys.Date(),sep="_")
dir.create(file.path(subDir, subDir_split), showWarnings = FALSE) # create if !exists
# get filepath split directory for export
filepath_split <- paste(currDir, subDir, subDir_split, sep="/")
# d. export csv
# add csv extension to name
exportName <- paste0(temp_name,".csv")
# add filename.csv to the end of filepath so it can be used in write.csv as path
filepath_split <- paste(filepath_split,exportName,sep="/")
# write concatenated csv, leave off row numbers
write.csv(temp_df, filepath_split, row.names=FALSE)
# d. return dataframe to global environment
assign(temp_name,temp_df,.GlobalEnv)
# e. except instructions, add all the dataframes to 'totalData'
if(temp_name!="instructions") {totalData <- rbind(totalData,temp_df)}
}
# total data
exportName <- paste0("totalData",".csv")
filepath_split <- paste(currDir, subDir, subDir_split, sep="/")
filepath_split <- paste(filepath_split,exportName,sep="/")
write.csv(totalData, filepath_split, row.names=FALSE)
}
split_by_trial_type(lgs)
rm(surveyData,testData,instructions,data_concat)
split_by_trial_type(lgs)
dataIllu <- read.csv("~/Desktop/illusions_all.csv")
rm(instructions, surveyData,testData)
split_by_trial_type(dataIllu, c("survey-text", "survey-likert"))
rm(surveyData)
# df could be a dataframe in the global environment OR a filepath to a csv
split_by_trial_type <- function(df, type_list = c("text", "single-stim", "survey-text")) {
# 1. check if df is a filepath ("character") or dataframe ("list")
if(typeof(df)=="character"){
setwd(dirname(df))
df <- read.csv(df) # setwd() to df's parent for saving future data
}
# some setup
type <- "trial_type" # CLDL standard colname for types
totalData <- data.frame() # empty dataframe for including data of type_list types
# 2. validate that inputs in correct format
validate_inputs <- function() {
# a. validate "trial_type" is col in df
if(type %in% names(df)) {
# b. validate types in type_list exist in type col
for (item in type_list) {
if(item %in% df[[type]]) {
# do nothing
} else {
print("ERR 1: one or more items in type_list were not found in dataframe")
return(FALSE)
}
}
}
else {
print("ERR 0: no column 'trial_type' found in dataframe, please name relevant column 'trial_type'")
return(FALSE)
}
return(TRUE) # return true if this point reached (return false would break from fxn early)
}
# ==== call fxn, continue only if validations return true! ====
if(validate_inputs() == FALSE){return(FALSE)} # return false breaks from the whole function early
# 3. separate data frames based on the type list, create a dataframe name/variable
for(item in type_list){
if(grepl("survey-text",item)){
temp_name <- "surveyData"
} else if (grepl("single-stim",item)){
temp_name <- "testData"
} else if (grepl("text", item)) {
temp_name <- "instructions"
} else if (grepl("categorize", item)) {
temp_name <- "trainingData"
} else {
temp_name <- paste(item, "Data", sep="") # if other type, just paste the type to Data
}
# b. create a dataframe for it by subsetting rows of that type
temp_df <- df[which(df[[type]]==item),]
# c. setup directory structure for exporting
# create or locate 'data' directory structure in the pwd
currDir <- getwd()
subDir <- "Data_processed"
dir.create(file.path(currDir, subDir), showWarnings = FALSE) # create data dir if !exists
# create sub directory for split data
subDir_split <- paste("data_split",Sys.Date(),sep="_")
dir.create(file.path(subDir, subDir_split), showWarnings = FALSE) # create if !exists
# get filepath split directory for export
filepath_split <- paste(currDir, subDir, subDir_split, sep="/")
# d. export csv
# add csv extension to name
exportName <- paste0(temp_name,".csv")
# add filename.csv to the end of filepath so it can be used in write.csv as path
filepath_split <- paste(filepath_split,exportName,sep="/")
# write concatenated csv, leave off row numbers
write.csv(temp_df, filepath_split, row.names=FALSE)
# d. return dataframe to global environment
assign(temp_name,temp_df,.GlobalEnv)
# e. except instructions, add all the dataframes to 'totalData'
if(temp_name!="instructions") {totalData <- rbind(totalData,temp_df)}
}
# total data
exportName <- paste0("totalData",".csv")
filepath_split <- paste(currDir, subDir, subDir_split, sep="/")
filepath_split <- paste(filepath_split,exportName,sep="/")
write.csv(totalData, filepath_split, row.names=FALSE)
}
split_by_trial_type(dataIllu, c("survey-text", "survey-likert"))
split_by_trial_type(dataIllu, c("survey-text", "survey-likert", "bob", "doo"))
split_by_trial_type(lgsX, c("text", "single-stim", "survey-text"))
library(devtools)
getwd()
setwd("~/git/cldl_repos_theRpackages/cldl")
setwd("~/git/cldl_repos/theRpackages/cldl")
document()
document()
setwd("..")
install("cldl")
cd ("./cldl")
setwd("./cldl")
document()
merge_and_split <- function(folder_path, type_list = c("text", "single-stim", "survey-text")) {
cldl::multimerge_vertical_csv(folder_path)
}
merge_and_split("~/Desktop/lgs2est")
rm(data_concat, lgs, survey-likertData, surveyData)
rm("data_concat, lgs, survey-likertData, surveyData)
rm("data_concat", lgs, survey-likertData, surveyData)
rm("data_concat", lgs, "survey-likertData", surveyData)
merge_and_split <- function(folder_path, type_list = c("text", "single-stim", "survey-text")) {
cldl::multimerge_vertical_csv(folder_path)
}
merge_and_split("~/Desktop/lgs2est")
getwd()
setwd("~/git/cldl_repos/theRpackages/cldl")
document()
setwd("..")
install("cldl")
merge_and_split <- function(folder_path, type_list = c("text", "single-stim", "survey-text")) {
cldl::multimerge_vertical_csv(folder_path)
}
merge_and_split("~/Desktop/lgs2est")
rm(data_concat)
rm(totalData)
merge_and_split <- function(folder_path, type_list = c("text", "single-stim", "survey-text")) {
cldl::multimerge_vertical_csv(folder_path)
# writes .csvs to data_preprocessed and setwd() to its parent
# returns totalData to .GlobalEnv
cldl::trial_type_split(totalData,type_list)
}
merge_and_split("~/Desktop/lgs2est")
getwd()
rm(surveyData, testData,totalData,instructions)
merge_and_split("~/Desktop/lgs2est", c("survey-text", "single-stim"))
setwd("~/git/cldl_repos/theRpackages/cldl")
document()
setwd("..")
install("cldl")
View(surveyData)
a <- "{"Q0"}"
a <- "{\"Q0\"}"
a
a <- '{\"Q0\"}'
a
a <- '{"Q0"}'
a
strsplit
strsplit(a, "{")
strsplit(a, "\"")
surveyData$responses[1]
b<- (surveyData$responses[1],"\"")
b <- (surveyData$responses[1,],"\"")
b <- surveyData[1,]$responses
b
strsplit(b,"\"")
strsplit(b, "\"")
strsplit(a, "\"")
strsplit(b, "\"")
b
a
strsplit(b, " ")
install.packages(jsonlite)
install.packages("jsonlite")
library(jsonlite)
mydf <- fromJSON(surveyData$responses)
surveyResponses <- surveyData$responses
surveyResponses <- as.data.frame(surveyData$responses)
View(surveyResponses)
mydf <- fromJSON(surveyResponses)
c <- fromJSON(b)
simplifyDataFrame
b
mydf <- fromJSON(surveyData[1,]$responses)
json <- fromJSON(surveyResponses)
View(surveyResponses)
json <-toJSON(surveyResponses)
json
mydf <- fromJSON(json)
View(mydf)
rm(testData,totalData,dataIllu,mydf, json, hi)
flatten(surveyResponses)
surveyResponses <- flatten(surveyResponses)
View(surveyResponses)
surveyResponses <- serializeJSON(surveyResponses)
surveyResponses <- data.frame(serializeJSON(surveyResponses))
View(surveyResponses)
surveyResponses <- as.data.frame(surveyData$responses)
rm(name)
rm(a)
test <- fromJSON(json_str = surveyData$responses)
test <- fromJSON(surveyData$responses)
test <- do.call(rbind.data.frame, lapply(surveyData$responses, jsonlite::fromJSON))
install.packages("RJSONIO")
library(RJSONIO)
test <- do.call(rbind.data.frame, lapply(surveyData$responses, RJSONIO::fromJSON))
test <- do.call(rbind.data.frame, lapply(surveyData$responses, FUN=function(x) {as.list(RJSONIO::fromJSON(x)))}))
test <- do.call(rbind.data.frame, lapply(surveyData$responses, FUN=function(x) {as.list(RJSONIO::fromJSON(x))}))
test <- do.call(rbind.data.frame, lapply(surveyData$responses, FUN=function(x) {as.list(jsonlite::fromJSON(x))}))
c <- jsonlite::fromJSON(b)
c <- jsonlite::fromJSON(b)
str(B)
str(b)
c <- fromJSON(b)
c <- str(B)
c <- str(b)
d <- fromJSON(c)
d <- fromJSON(c)
rm(c)
c <- toJSON(b)
d <- fromJSON(c)
d
rm(c,d)
c <- as.character(b)
d <- fromJSON(c)
d
d <- as.data.frame(d)
View(d)
rm(surveyResponess)
rm(surveyResponses)
surveyResponses <- as.data.frame(surveyData$responses)
surveyResponses <- as.data.frame(surveyData$responses)
surveyResponses <- as.character(surveyResponses)
mydf <- fromJSON(surveyResponses)
surveyResponses
surveyResponses <- as.data.frame(surveyData$responses)
surveyResponses <- as.character(surveyResponses)
surveyResponses <- as.data.frame(surveyData$responses)
View(surveyResponses)
d <- as.data.frame(jsonlite::fromJSON(c))
d
for(i in 1:nrow(surveyResponses)) {
row <- surveyResponses[i,]
# do stuff with row
newrow <- as.character(row)
newrow <- fromJSON(newrow)
}
newrow
for(i in 1:nrow(surveyResponses)) {
row <- surveyResponses[i,]
# do stuff with row
newrow <- as.character(row)
newrow <- as.data.frame(fromJSON(newrow))
df <- rbind(newrow, x)
}
View(newrow)
surveyResponses <- surveyData$responses
surveyResponses <- as.character(surveyResponses)
surveyResponses <- as.character(surveyResponses)
surveyResponses <- as.character(surveyResponses)
mydf <- fromJSON(surveyResponses)
for(i in 1:nrow(surveyResponses)) {
row <- surveyResponses[i,]
# do stuff with row
newrow <- as.character(row)
newrow <- as.data.frame(fromJSON(newrow))
df <- rbind(newrow, x)
}
View(newrow)
a <- surveyData[2,]$responses
a <- surveyData[2,]$responses
a <- as.character(a)
a <- as.data.frame(jsonlite::fromJSON(a))
e <- rbind.data.frame(a,d)
View(e)
for cell in 1:nrow(surveyData$responses) {
cell <- as.character(cell)
cell <- as.data.frame(jsonlite::fromJSON(cell))
rbind.data.frame(cell, e)
}
# can we make a for loop?
for(cell in 1:nrow(surveyData$responses)) {
cell <- as.character(cell)
cell <- as.data.frame(jsonlite::fromJSON(cell))
rbind.data.frame(cell, e)
}
nrow(surveyData$responses)
nrow(e)
for(i in 1:nrow(surveyData)) {
cell <- surveyData$responses[i, ]
cell <- as.character(cell)
cell <- as.data.frame(jsonlite::fromJSON(cell))
rbind.data.frame(cell, e)
}
nrow(surveyData)
surveyData$responses[1,]
for(i in 1:nrow(surveyData)) {
cell <- surveyData[i,]$responses
cell <- as.character(cell)
cell <- as.data.frame(jsonlite::fromJSON(cell))
rbind.data.frame(cell, e)
}
View(surveyData)
View(newrow)
View(e)
View(d)
View(cell)
View(d)
getjson <- function(i, df, colname) {
newdf <- df[i,colname]
newdf <- as.character(newdf)
newdf <- as.data.frame(jsonlite::fromJSON(newdf))
}
getjson(2,surveyData,"responses")
getjson <- function(i, df, colname) {
newdf <- df[i,colname]
newdf <- as.character(newdf)
newdf <<- as.data.frame(jsonlite::fromJSON(newdf))
}
getjson(2,surveyData,"responses")
View(newrow)
View(newdf)
View(newrow)
View(newdf)
emptydf <- data.frame()
getjson <- function(i, df, colname) {
newdf <- df[i,colname]
newdf <- as.character(newdf)
newdf <- as.data.frame(jsonlite::fromJSON(newdf))
rbind.data.frame(emptydf, newdf)
}
getjs
emptydf <- data.frame()
getjson <- function(i, df, colname) {
newdf <- df[i,colname]
newdf <- as.character(newdf)
newdf <- as.data.frame(jsonlite::fromJSON(newdf))
rbind.data.frame(emptydf, newdf)
}
lapply(c(1,2,3), function(x) getjson(x,surveyData,"responses"))
# let's try to abstract a bit
emptydf <- data.frame()
getjson <- function(i, df, colname) {
newdf <- df[i,colname]
newdf <- as.character(newdf)
newdf <- as.data.frame(jsonlite::fromJSON(newdf))
emptydf <<- rbind.data.frame(emptydf, newdf)
}
lapply(c(1,2,3), function(x) getjson(x,surveyData,"responses"))
View(emptydf)
lapply(1:nrow(surveyData), function(x) getjson(x, surveyData, "responses"))
View(emptydf)
